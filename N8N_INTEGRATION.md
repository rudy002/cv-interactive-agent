# üîó Int√©gration n8n - Guide de Configuration

## üìã Ce qui a √©t√© fait

‚úÖ Route API Next.js cr√©√©e (`/app/api/chat/route.ts`)
‚úÖ Composant Chat mis √† jour pour appeler l'API
‚úÖ Gestion des erreurs et √©tat de chargement
‚úÖ Indicateur visuel pendant le chargement

## üöÄ √âtapes pour finaliser l'int√©gration

### 1. Configurer les variables d'environnement

Cr√©ez un fichier `.env.local` √† la racine du projet :

```bash
cp .env.example .env.local
```

Modifiez `.env.local` avec vos vraies valeurs :

```env
N8N_WEBHOOK_URL=https://votre-instance-n8n.com/webhook/chat
# Si vous avez une cl√© API :
# N8N_API_KEY=votre_cle_api
```

### 2. Configurer votre workflow n8n

Votre workflow n8n doit :

#### Entr√©e (Webhook) :
- **M√©thode** : POST
- **Corps attendu** :
  ```json
  {
    "message": "Question de l'utilisateur",
    "conversationHistory": [...],
    "timestamp": "2024-01-01T00:00:00.000Z"
  }
  ```

#### Sortie (Response) :
Votre workflow doit retourner une r√©ponse au format JSON :

**Option 1** (recommand√©e) :
```json
{
  "response": "La r√©ponse de votre assistant IA"
}
```

**Option 2** :
```json
{
  "output": "La r√©ponse de votre assistant IA"
}
```

**Option 3** :
```json
{
  "message": "La r√©ponse de votre assistant IA"
}
```

### 3. Structure typique d'un workflow n8n RAG

```
Webhook (Trigger)
    ‚Üì
Extraire le message
    ‚Üì
Recherche vectorielle (Pinecone/Supabase/autre)
    ‚Üì
Pr√©parer le prompt avec contexte
    ‚Üì
Appel LLM (OpenAI/Anthropic/autre)
    ‚Üì
Formater la r√©ponse
    ‚Üì
Retourner la r√©ponse
```

### 4. Adapter le code si n√©cessaire

Si votre n8n retourne un format diff√©rent, modifiez `app/api/chat/route.ts` ligne 32-34 :

```typescript
// Actuellement :
message: data.response || data.output || data.message || data,

// Adaptez selon votre format n8n
```

### 5. Tester l'int√©gration

1. D√©marrez votre serveur de d√©veloppement :
```bash
npm run dev
```

2. Ouvrez votre navigateur sur `http://localhost:3000`

3. Envoyez un message de test

4. V√©rifiez :
   - Les logs de la console du navigateur (F12)
   - Les logs de votre workflow n8n
   - La r√©ponse affich√©e dans le chat

### 6. Debug

Si √ßa ne fonctionne pas :

1. **V√©rifier l'URL du webhook** :
   ```bash
   # Tester directement avec curl
   curl -X POST https://votre-n8n-instance.com/webhook/chat \
     -H "Content-Type: application/json" \
     -d '{"message":"test"}'
   ```

2. **V√©rifier les CORS** :
   Dans n8n, assurez-vous que votre webhook accepte les requ√™tes depuis votre domaine

3. **V√©rifier les logs** :
   - Console navigateur (F12 ‚Üí Console)
   - Terminal du serveur Next.js
   - Logs n8n

## üìù Notes importantes

- Le fichier `.env.local` ne doit JAMAIS √™tre commit√© dans Git
- Assurez-vous que votre workflow n8n est activ√©
- Pour la production, utilisez les variables d'environnement de votre h√©bergeur

## üîí S√©curit√©

Pour s√©curiser votre endpoint n8n :

1. Ajoutez une authentification dans n8n
2. Utilisez `N8N_API_KEY` dans `.env.local`
3. D√©commentez la ligne 20 dans `app/api/chat/route.ts` :
   ```typescript
   'Authorization': `Bearer ${process.env.N8N_API_KEY}`,
   ```

## ‚ùì Besoin d'aide ?

Si vous rencontrez des probl√®mes, partagez :
- Les logs d'erreur du navigateur
- Les logs de n8n
- Une capture d'√©cran de votre workflow n8n

